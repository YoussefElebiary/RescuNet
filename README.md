# RescuNet

<div align="center" style="padding: 0; margin: 0; top: 0;">
  <img src="./assets/rescunet.png" alt="RescuNet Text" width="300" />
  <p><b>Next-Gen Disaster Response Intelligence</b></p>
  <p>
    <a href="#key-features">Key Features</a> â€¢
    <a href="#tech-stack">Tech Stack</a> â€¢
    <a href="#installation">Installation</a> â€¢
    <a href="#usage">Usage</a> â€¢
    <a href="#license">License</a>
  </p>
</div>

---

RescuNet is a comprehensive platform designed to revolutionize emergency response operations. By integrating AI-powered aerial surveillance, advanced graph-based routing, and real-time text analysis, RescuNet empowers responders to locate survivors, identify hazards, and navigate complex disaster zones with unprecedented efficiency.

## Key Features

### ğŸ—ºï¸ Graph Routing
- **Smart Pathfinding**: Leverages **Graph Neural Networks (GNN)** to predict edge safety and travel costs dynamically.
- **Hybrid Solver**: Features a high-performance **C++ Routing Engine** with a robust Python fallback to calculate optimal rescue paths.
- **Interactive Map**: Plan missions, manage nodes, and visualize routes using **MapLibre GL JS**.

<div align="center" style="padding: 0; margin: 0; top: 0;">
  <img src="./assets/route.png" alt="Route Planner Screenshot" />
  <br>
  <i>Interactive Mission Planning Map</i>
</div>

### ğŸš Aerial Intelligence
- **Real-Time Detection**: Utilizes **YOLOv11** to detect survivors and fire hazards instantly from drone video feeds.
- **Dual-Mode Surveillance**: Supports both **Thermal** (Person Detection) and **RGB** (Fire Detection) modes for versatile operation.
- **Low-Latency Streaming**: WebSocket-based architecture ensures real-time video transmission and processing.

<div align="center" style="padding: 0; margin: 0; top: 0;">
  <img src="./assets/live_feed.png" alt="Live Drone Feed with Object Detection" />
  <br>
  <i>Live Drone Feed with Object Detection</i>
</div>

### ğŸ’¬ Text Analysis
- **Two-Stage Classification Pipeline**:
  1. **Fake News Detection**: The first model filters out fake or spam reports. If a report is flagged as fake, it is immediately returned.
  2. **Emergency Classification**: Valid reports are passed to a second model to determine if they constitute a genuine emergency or a non-emergency situation.

<div align="center" style="padding: 0; margin: 0; top: 0;">
  <img src="./assets/text_analysis.png" alt="Text Analysis Screenshot" />
  <br>
  <i>Emergency Text Classification Interface</i>
</div>

## Tech Stack

- **Backend**: FastAPI, Python 3.9
- **Core Logic**: C++, PyBind11, OSMNx, NetworkX
- **AI / ML**: PyTorch, PyTorch Geometric, Ultralytics YOLO
- **Frontend**: HTML5, JavaScript (ES6+), TailwindCSS, MapLibre GL JS
- **Dependency Management**: Pipenv

## Installation

### Prerequisites
- Python 3.9 or higher
- Pipenv (`pip install pipenv`)
- C++ Compiler (GCC/Clang/MSVC) for the routing engine

### 1. Backend Setup

Navigate to the backend directory and install dependencies:

```bash
cd backend
pipenv install
pipenv shell
```

### 2. Build C++ Routing Engine

Compile the high-performance C++ solver extension:

```bash
cd cpp_router
pip install .
cd ..
```

### 3. Frontend Setup

No build step is required for the frontend as it uses vanilla JS and CDN-hosted libraries.

## Usage

### Start the Backend Server
Run the following command from within the `backend` directory (ensure your virtual environment is active):

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`.
- **API Documentation**: `http://localhost:8000/docs`
- **Health Check**: `http://localhost:8000/api/health`

### Launch the Frontend
Open `frontend/index.html` in your web browser.

> **Note**: For the best experience and to avoid CORS issues with local file access, it is recommended to serve the frontend using a local development server (e.g., "Live Server" extension in VS Code or `python -m http.server`).

## Project Structure

```
RescuNet/
â”œâ”€â”€ assets/                    # Project screenshots and logos
â”œâ”€â”€ backend/                   # FastAPI application
â”‚   â”œâ”€â”€ app/                   # Main application logic and endpoints
â”‚   â”œâ”€â”€ models/                # GNN and YOLO model definitions
â”‚   â”œâ”€â”€ router/                # Routing logic (Python & C++)
â”‚   â”œâ”€â”€ docs/                  # Backend documentation
â”‚   â””â”€â”€ Pipfile                # Python dependencies
â”œâ”€â”€ frontend/                  # User Interface
â”‚   â”œâ”€â”€ static/                # CSS, JS, and image assets
â”‚   â”œâ”€â”€ index.html             # Landing page
â”‚   â”œâ”€â”€ camera.html            # Live surveillance feed
â”‚   â”œâ”€â”€ route.html             # Mission planning map
â”‚   â”œâ”€â”€ text_analysis.html     # Text classification tool
â”‚   â””â”€â”€ drone_simulation.html  # Drone simulation (accessible via URL only)
â”œâ”€â”€ LICENSE                    # Project license file
â””â”€â”€ README.md                  # Project documentation
```

## Authors

| Name            | Role                                      |
|-----------------|-------------------------------------------|
| [Youssef Elebiary](https://github.com/YoussefElebiary)| Graph Routing Engine (GNN & C++) & Fullstack Development |
| [Akram Tarek](https://github.com/Akramz1)     | Text Analysis ML Models                   |
| [Ahmed Ghazaly](https://github.com/ghazaly118) | Text Analysis ML Models                   |
| [Amr Hassan](https://github.com/amr1372003)      | Object Detection AI Models                |
| [Mohamed Maher](https://github.com/Maherr11)   | Object Detection AI Models                |

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **Ultralytics** for the YOLO models.
- **OSMNx** for simplifying OpenStreetMap graph retrieval.
- **MapLibre** for the open-source mapping library.
